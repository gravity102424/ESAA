{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjj5PfPOAxocwGUwS7uR3R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gravity102424/ESAA/blob/main/ESAA_YB_week13_2_review_%EB%8D%B0%EC%9D%B4%EC%BD%98_x_BDA_%ED%95%99%EC%8A%B5%EC%9E%90_%EC%88%98%EB%A3%8C_%EC%98%88%EC%B8%A1_AI_%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이콘 x BDA 학습자 수료 예측 AI 경진대회\n",
        "\n",
        "https://dacon.io/competitions/official/236519/overview/description\n",
        "\n",
        "## 수장작 리뷰\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 1) 대회 주제 및 데이터 개요\n",
        "\n",
        "**대회 주제**\n",
        "\n",
        "* 학습자의 **수료 여부를 예측하는 AI 모델 개발**이 목표였던 **수료 예측 분류 문제**이다.\n",
        "* BDA(Big Data Analysis) 8기 학습자 데이터를 기반으로 9기 학습자의 수료 여부를 예측하는 **정형 데이터 분류 문제**이다.\n",
        "\n",
        "**데이터 성격**\n",
        "\n",
        "* 개인별 학습 설문/행동 정보(?) 등을 포함한 **구조화된 테이블 데이터**이다.\n",
        "* 클래스 불균형 현상이 매우 큰 데이터로, **수료(1)** 비율이 약 **70%**, **미수료(0)**가 약 **30%**로 나타났다.\n",
        "\n",
        "**목표 평가 지표**\n",
        "\n",
        "* **F1 Score**를 기준으로 성능을 평가\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 2) 공유된 코드 요약 및 리뷰\n",
        "\n",
        "공유자는 **SVM (Support Vector Machine)** 기반 모델을 최종 솔루션으로 선택했고, 다음과 같은 방식으로 구현한다.\n",
        "\n",
        "### ✔️ (1) 모델 선택\n",
        "\n",
        "* SVM 모델을 채택\n",
        "  ➤ 특히 **class_weight** 조정으로 불균형 데이터 환경에서 소수 클래스(미수료)도 예측하려고 시도했다.\n",
        "* 이유:\n",
        "\n",
        "  * 데이터 크기가 크지 않았고,\n",
        "  * SVM은 작은 데이터에서도 과적합 위험이 적고 안정적이라고 판단.\n",
        "\n",
        "👉 **리뷰 포인트**\n",
        "\n",
        "* SVM은 구조화된 데이터 + 중간 규모 데이터에 적절하긴 하나, 불균형 context에서 성능이 반드시 좋은 모델은 아님.\n",
        "* 그렇지만 class_weight 조정을 통해 어느 정도 대응하려 한 점은 타당\n",
        "\n",
        "---\n",
        "\n",
        "### ✔️ (2) Feature 전처리\n",
        "\n",
        "**전처리 순서 요약**\n",
        "\n",
        "1. **결측률 높은 변수 제거**\n",
        "2. **Label Encoding** (범주형 → 숫자)\n",
        "3. **SimpleImputer**로 결측값 보완\n",
        "4. **StandardScaler**로 정규화\n",
        "5. **SelectKBest**로 중요한 변수 선택 후 학습에 활용\n",
        "\n",
        "👉 **리뷰 포인트**\n",
        "\n",
        "* 파이프라인 구성은 깔끔하고 기본적이며, 범주형 처리 → 스케일링 → 선택적 특성 선택으로 이어지는 전형적인 ML 워크플로우\n",
        "* 다만 **더 복잡한 파생특성(feature engineering)** 시도는 큰 성능 향상으로 이어지지 않았다.\n",
        "---\n",
        "\n",
        "### ✔️ (3) 클래스 불균형 대응\n",
        "\n",
        "* **Oversampling / Undersampling / StratifiedKFold / 앙상블** 등 다양한 방법 시도했지만 성능 개선이 크지 않았음.\n",
        "* **class_weight** 조정과 **예측 threshold를 0.8**로 높게 설정 → 예측 편향 완화 시도함.\n",
        "\n",
        "👉 **리뷰 포인트**\n",
        "\n",
        "* 불균형 데이터 문제는 모든 참가자에게 핵심 이슈였고, 단순 oversampling만으로 해결이 어려운 것으로 보였다.\n",
        "---\n",
        "\n",
        "## 🌟 3) 이 코드의 **차별점**\n",
        "\n",
        "✔️ **클래식 ML 접근** 집중\n",
        "\n",
        "* Kaggle/데이콘에서 많이 쓰는 XGBoost/LightGBM/CatBoost보다\n",
        "* SVM을 선택해 class_weight 조정과 threshold 튜닝까지 직접 최적화한 점이 특징이다.\n",
        "\n",
        "✔️ **전처리 → 변수 선택 흐름 구체화**\n",
        "\n",
        "* 단순 모델 학습이 아닌 피처 선택까지 연결한 워크플로우를 구성한 점\n",
        "\n",
        "✔️ **threshold 변경을 통한 F1 향상 시도**\n",
        "\n",
        "* Soft classification 모델에서 threshold를 기본(0.5)에서 변형한 점이 좋았다.\n",
        "\n",
        "---\n",
        "\n",
        "## 📘 4) 이 코드에서 **배울 점**\n",
        "\n",
        "### ✔️ 전처리 파이프라인 정리\n",
        "\n",
        "* Label Encoding → Imputation → Scaler → Feature Selection\n",
        "  ➤ 표준 전처리 흐름을 이해 • 구현하는 데 도움이 된다.\n",
        "\n",
        "### ✔️ 클래스 불균형 문제 대응\n",
        "\n",
        "* 단순 오버샘플링보다 **class_weight**나 **threshold 조정** 같은 기본 튜닝이 먼저 고려되어야 함을 보여준다.\n",
        "\n",
        "### ✔️ 모델 설명 및 선택 기준 정리\n",
        "\n",
        "* 데이터 크기가 크지 않거나,\n",
        "* 불균형 문제가 복잡할 때 어떤 모델을 선택할지 결정하는 과정(장/단점 비교)을 기록한 점이 참고가 된다.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "XUxgMO2To2YU"
      }
    }
  ]
}